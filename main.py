import time
import logging
import json
import os
from pathlib import Path
from selenium.webdriver.common.by import By
from src.chrome_driver import ChromeDriver
from src.naver_shopping import OptimizedNaverCrawler


def load_config(config_path="config/config.json"):
    """config.json íŒŒì¼ ë¡œë“œ"""
    try:
        config_file = Path(config_path)
        if not config_file.exists():
            print(f"âš ï¸ ì„¤ì • íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {config_path}")
            print("ê¸°ë³¸ ì„¤ì •ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")
            return {
                "headless": False,
                "wait_time": 3,
                "timeout": 10,
                "use_debug_mode": True,
                "debug_port": 9222,
                "profile_path": None
            }
        
        with open(config_file, 'r', encoding='utf-8') as f:
            config = json.load(f)
            print(f"âœ… ì„¤ì • íŒŒì¼ ë¡œë“œ ì™„ë£Œ: {config_path}")
            return config
    except Exception as e:
        print(f"âŒ ì„¤ì • íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {e}")
        print("ê¸°ë³¸ ì„¤ì •ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")
        return {
            "headless": False,
            "wait_time": 3,
            "timeout": 10,
            "use_debug_mode": True,
            "debug_port": 9222,
            "profile_path": None
        }


def test_crawler(url_list: dict = {}, config=None):
    """
    í¬ë¡¤ëŸ¬ í…ŒìŠ¤íŠ¸ (naver_shopping.py ì‚¬ìš©)
    
    Args:
        url_list: í…ŒìŠ¤íŠ¸í•  URL ë”•ì…”ë„ˆë¦¬ (í‚¤ì›Œë“œ: URL)
        config: ì„¤ì • ë”•ì…”ë„ˆë¦¬ (Noneì´ë©´ ìë™ ë¡œë“œ)
    """
    # ì„¤ì • ë¡œë“œ
    if config is None:
        config = load_config()
    
    print(f"\n{'='*60}")
    print(f"ğŸ” í¬ë¡¤ëŸ¬ í…ŒìŠ¤íŠ¸ ì‹œì‘")
    print(f"ğŸ” í‚¤ì›Œë“œ ê°œìˆ˜: {len(url_list)}")
    print(f"{'='*60}")
    print(f"\nğŸ“‹ í˜„ì¬ ì„¤ì •:")
    print(f"  - í—¤ë“œë¦¬ìŠ¤ ëª¨ë“œ: {config.get('headless', False)}")
    print(f"  - ë””ë²„ê¹… ëª¨ë“œ: {config.get('use_debug_mode', True)} (VBA ì›ë³¸ ë°©ì‹)")
    if config.get('use_debug_mode', True):
        print(f"  - ë””ë²„ê¹… í¬íŠ¸: {config.get('debug_port', 9222)}")
        profile_path = config.get('profile_path') or os.path.expanduser("~/ChromeTEMP")
        print(f"  - í”„ë¡œí•„ ê²½ë¡œ: {profile_path}")
    print(f"  - ëŒ€ê¸° ì‹œê°„: {config.get('wait_time', 3)}ì´ˆ")
    print(f"  - íƒ€ì„ì•„ì›ƒ: {config.get('timeout', 10)}ì´ˆ")
    print(f"{'='*60}\n")
    
    # ë¡œê¹… ì„¤ì •
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(levelname)s - %(message)s'
    )
    
    # ğŸ†• ëª¨ë“  í‚¤ì›Œë“œì— ëŒ€í•´ ë°˜ë³µ ì²˜ë¦¬
    if not url_list:
        print("âš ï¸  ì²˜ë¦¬í•  URLì´ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    keywords = list(url_list.keys())
    total_keywords = len(keywords)
    
    for idx, keyword in enumerate(keywords, 1):
        print(f"\n{'='*60}")
        print(f"ğŸ”„ í‚¤ì›Œë“œ {idx}/{total_keywords}: '{keyword}'")
        print(f"{'='*60}")
        
        url = url_list[keyword]
        
        # ê° í‚¤ì›Œë“œë§ˆë‹¤ ìƒˆë¡œìš´ ë“œë¼ì´ë²„ ìƒì„±
        chrome = ChromeDriver(
            headless=config.get("headless", False),
            use_debug_mode=config.get("use_debug_mode", True),
            debug_port=config.get("debug_port", 9222),
            profile_path=config.get("profile_path")  # Noneì´ë©´ ìë™ìœ¼ë¡œ ~/ChromeTEMP
        )

        driver = chrome.create_driver()
        
        # ChromeDriver ê°ì²´ì— driver ì†ì„± ì¶”ê°€ (OptimizedNaverCrawlerì—ì„œ ì‚¬ìš©)
        chrome.driver = driver
        
        # OptimizedNaverCrawler ìƒì„± (naver_shopping.py)
        crawler = OptimizedNaverCrawler(chrome_controller=chrome)

        try:
            # ì²« ë²ˆì§¸ í‚¤ì›Œë“œì¼ ë•Œë§Œ ë¡œê·¸ì¸ ì•ˆë‚´
            if idx == 1:
                print("\n1ï¸âƒ£ ë„¤ì´ë²„ ë¡œê·¸ì¸ (ì„ íƒì‚¬í•­)")
                print("  - ë¡œê·¸ì¸ì´ í•„ìš”í•œ ê²½ìš° ë¸Œë¼ìš°ì €ì—ì„œ ìˆ˜ë™ìœ¼ë¡œ ë¡œê·¸ì¸í•´ì£¼ì„¸ìš”.")
                # input("  - ë¡œê·¸ì¸ì„ ê±´ë„ˆë›°ë ¤ë©´ ì—”í„°ë¥¼ ëˆ„ë¥´ì„¸ìš”...")
            
            print(f"\n2ï¸âƒ£ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸: '{keyword}'")
            
            # naver_shopping.pyì˜ _natural_search ì‚¬ìš©
            # ìë™ìœ¼ë¡œ ë„¤ì´ë²„ ë©”ì¸ â†’ í†µí•©ê²€ìƒ‰ â†’ ì‡¼í•‘ íƒ­ í´ë¦­
            crawler._natural_search(keyword=keyword, domestic=True)
            
            # ìƒí’ˆ ëª©ë¡ ë¡œë”©
            crawler._fast_lazy_load()

            # URLì—ì„œ UID ì¶”ì¶œ
            target_uid = crawler.extract_uid_from_url(url)
            
            if target_uid:
                print(f"\n3ï¸âƒ£ ëª©í‘œ ìƒí’ˆ ì°¾ê¸°")
                print(f"  - URL: {url}")
                print(f"  - UID (nv_mid): {target_uid}")
                
                # nv_midë¡œ ìƒí’ˆ ì°¾ì•„ì„œ í´ë¦­
                success = crawler.find_and_click_product_by_uid(target_uid)
                
                if success:
                    print(f"\nâœ… ìƒí’ˆ í˜ì´ì§€ë¡œ ì´ë™ ì„±ê³µ!")
                    print(f"  ğŸ”— í˜„ì¬ URL: {driver.current_url}")
                    
                    # ì ì‹œ ëŒ€ê¸° (ì‚¬ìš©ìê°€ ê²°ê³¼ í™•ì¸ ê°€ëŠ¥)
                    time.sleep(2)
                else:
                    print(f"\nâš ï¸  ìƒí’ˆì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
            else:
                print(f"\nâš ï¸  URLì—ì„œ UIDë¥¼ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {url}")
                
                # UID ì¶”ì¶œ ì‹¤íŒ¨ ì‹œ ê¸°ì¡´ ë°©ì‹ìœ¼ë¡œ ì§„í–‰
                print("\n3ï¸âƒ£ ê°€ê²©ë¹„êµ ìƒí’ˆ ë°ì´í„° ì¶”ì¶œ")
                data = crawler._extract_store_data(page=1)
                
                if data:
                    print(f"\nâœ… {len(data)}ê°œ ìŠ¤í† ì–´ ì¶”ì¶œ ì™„ë£Œ!")
                    print(f"\nğŸ“Š ì¶”ì¶œëœ ë°ì´í„° ìƒ˜í”Œ (ì²˜ìŒ 3ê°œ):")
                    for i, item in enumerate(data[:3], 1):
                        print(f"\n[{i}]")
                        print(f"  ìƒí’ˆëª…: {item.get('ìƒí’ˆëª…', 'N/A')[:50]}")
                        print(f"  ìŠ¤í† ì–´: {item.get('ì´ë¦„', 'N/A')}")
                        print(f"  ìˆœìœ„: {item.get('ranking', 'N/A')}")
                        print(f"  ê´‘ê³ : {item.get('ê´‘ê³ ', 'N/A')}")
                        print(f"  ë¦¬ë·°ìˆ˜: {item.get('ë¦¬ë·°ìˆ˜', 'N/A')}")
                        print(f"  ì°œìˆ˜: {item.get('ì°œìˆ˜', 'N/A')}")
                else:
                    print("\nâš ï¸  ë°ì´í„° ì¶”ì¶œ ì‹¤íŒ¨")
            
            print(f"\nâœ… í‚¤ì›Œë“œ '{keyword}' ì²˜ë¦¬ ì™„ë£Œ!")
            
        except Exception as e:
            print(f"\nâŒ í‚¤ì›Œë“œ '{keyword}' ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            import traceback
            traceback.print_exc()
            
        finally:
            print(f"\në“œë¼ì´ë²„ ì¢…ë£Œ ì¤‘... ({idx}/{total_keywords})")
            # Chrome í”„ë¡œì„¸ìŠ¤ê¹Œì§€ ì™„ì „íˆ ì¢…ë£Œ (ë‹¤ìŒ í‚¤ì›Œë“œ ì²˜ë¦¬ë¥¼ ìœ„í•´)
            chrome.quit_driver(driver, kill_chrome=True)
            print("âœ… ë“œë¼ì´ë²„ ì¢…ë£Œ ì™„ë£Œ!")
            
            # ë‹¤ìŒ í‚¤ì›Œë“œê°€ ìˆìœ¼ë©´ ì ì‹œ ëŒ€ê¸° (Chrome í”„ë¡œì„¸ìŠ¤ ì •ë¦¬ ì‹œê°„)
            if idx < total_keywords:
                print("\nâ³ ë‹¤ìŒ í‚¤ì›Œë“œ ì¤€ë¹„ ì¤‘...")
                time.sleep(3)  # Chrome í”„ë¡œì„¸ìŠ¤ê°€ ì™„ì „íˆ ì¢…ë£Œë  ì‹œê°„ í™•ë³´
    
    print(f"\n{'='*60}")
    print(f"ğŸ‰ ëª¨ë“  í‚¤ì›Œë“œ ì²˜ë¦¬ ì™„ë£Œ! (ì´ {total_keywords}ê°œ)")
    print(f"{'='*60}")
    # input("\nì—”í„°ë¥¼ ëˆ„ë¥´ë©´ ì¢…ë£Œí•©ë‹ˆë‹¤...")



if __name__ == "__main__":
    # config.json ì„¤ì • ë¡œë“œ
    config = load_config()
    
    url_list = {
        # "í•œìš°ì„ ë¬¼ì„¸íŠ¸": "https://brand.naver.com/gorgeouscowofficial/products/9687826363",
        "í•œìš°ì„ ë¬¼ì„¸íŠ¸": "https://smartstore.naver.com/the_homme/products/11629672050",
        "ë‹¤ì´ì–´ë¦¬": "https://search.shopping.naver.com/catalog/57407585768",
        "ë°”ë””ìŠ¤í¬ëŸ½": "https://smartstore.naver.com/braziliansecret/products/636183671",
    }
    
    # í¬ë¡¤ëŸ¬ í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    test_crawler(url_list=url_list, config=config)
