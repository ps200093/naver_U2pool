import time
import logging
import json
import os
from pathlib import Path
from selenium.webdriver.common.by import By
from src.chrome_driver import ChromeDriver
from src.naver_shopping import OptimizedNaverCrawler


def load_config(config_path="config/config.json"):
    """config.json íŒŒì¼ ë¡œë“œ"""
    try:
        config_file = Path(config_path)
        if not config_file.exists():
            print(f"âš ï¸ ì„¤ì • íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {config_path}")
            print("ê¸°ë³¸ ì„¤ì •ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")
            return {
                "headless": False,
                "wait_time": 3,
                "timeout": 10,
                "use_debug_mode": True,
                "debug_port": 9222,
                "profile_path": None
            }
        
        with open(config_file, 'r', encoding='utf-8') as f:
            config = json.load(f)
            print(f"âœ… ì„¤ì • íŒŒì¼ ë¡œë“œ ì™„ë£Œ: {config_path}")
            return config
    except Exception as e:
        print(f"âŒ ì„¤ì • íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {e}")
        print("ê¸°ë³¸ ì„¤ì •ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")
        return {
            "headless": False,
            "wait_time": 3,
            "timeout": 10,
            "use_debug_mode": True,
            "debug_port": 9222,
            "profile_path": None
        }


def test_crawler(url_list: dict = {}, config=None):
    """
    í¬ë¡¤ëŸ¬ í…ŒìŠ¤íŠ¸ (naver_shopping.py ì‚¬ìš©)
    
    Args:
        url_list: í…ŒìŠ¤íŠ¸í•  URL ë”•ì…”ë„ˆë¦¬ (í‚¤ì›Œë“œ: URL)
        config: ì„¤ì • ë”•ì…”ë„ˆë¦¬ (Noneì´ë©´ ìë™ ë¡œë“œ)
    """
    # ì„¤ì • ë¡œë“œ
    if config is None:
        config = load_config()
    
    print(f"\n{'='*60}")
    print(f"ğŸ” í¬ë¡¤ëŸ¬ í…ŒìŠ¤íŠ¸ ì‹œì‘")
    print(f"ğŸ” í‚¤ì›Œë“œ ê°œìˆ˜: {len(url_list)}")
    print(f"{'='*60}")
    print(f"\nğŸ“‹ í˜„ì¬ ì„¤ì •:")
    print(f"  - í—¤ë“œë¦¬ìŠ¤ ëª¨ë“œ: {config.get('headless', False)}")
    print(f"  - ë””ë²„ê¹… ëª¨ë“œ: {config.get('use_debug_mode', True)} (VBA ì›ë³¸ ë°©ì‹)")
    if config.get('use_debug_mode', True):
        print(f"  - ë””ë²„ê¹… í¬íŠ¸: {config.get('debug_port', 9222)}")
        profile_path = config.get('profile_path') or os.path.expanduser("~/ChromeTEMP")
        print(f"  - í”„ë¡œí•„ ê²½ë¡œ: {profile_path}")
    print(f"  - ëŒ€ê¸° ì‹œê°„: {config.get('wait_time', 3)}ì´ˆ")
    print(f"  - íƒ€ì„ì•„ì›ƒ: {config.get('timeout', 10)}ì´ˆ")
    print(f"{'='*60}\n")
    
    # ë¡œê¹… ì„¤ì •
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(levelname)s - %(message)s'
    )
    
    # ë“œë¼ì´ë²„ ìƒì„± (config ì„¤ì • ì ìš©)
    chrome = ChromeDriver(
        headless=config.get("headless", False),
        use_debug_mode=config.get("use_debug_mode", True),
        debug_port=config.get("debug_port", 9222),
        profile_path=config.get("profile_path")  # Noneì´ë©´ ìë™ìœ¼ë¡œ ~/ChromeTEMP
    )

    driver = chrome.create_driver()
    
    # ChromeDriver ê°ì²´ì— driver ì†ì„± ì¶”ê°€ (OptimizedNaverCrawlerì—ì„œ ì‚¬ìš©)
    chrome.driver = driver
    
    # OptimizedNaverCrawler ìƒì„± (naver_shopping.py)
    crawler = OptimizedNaverCrawler(chrome_controller=chrome)

    try:
        print("\n1ï¸âƒ£ ë„¤ì´ë²„ ë¡œê·¸ì¸ (ì„ íƒì‚¬í•­)")
        print("  - ë¡œê·¸ì¸ì´ í•„ìš”í•œ ê²½ìš° ë¸Œë¼ìš°ì €ì—ì„œ ìˆ˜ë™ìœ¼ë¡œ ë¡œê·¸ì¸í•´ì£¼ì„¸ìš”.")
        input("  - ë¡œê·¸ì¸ì„ ê±´ë„ˆë›°ë ¤ë©´ ì—”í„°ë¥¼ ëˆ„ë¥´ì„¸ìš”...")

        if url_list:
            keywords = list(url_list.keys())
            first_keyword = keywords[0]
            first_url = url_list[first_keyword]
            
            print(f"\n2ï¸âƒ£ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸: '{first_keyword}'")
            
            # naver_shopping.pyì˜ _natural_search ì‚¬ìš©
            # ìë™ìœ¼ë¡œ ë„¤ì´ë²„ ë©”ì¸ â†’ í†µí•©ê²€ìƒ‰ â†’ ì‡¼í•‘ íƒ­ í´ë¦­
            crawler._natural_search(keyword=first_keyword, domestic=True)
            
            # ğŸ†• URLì—ì„œ UID ì¶”ì¶œ
            crawler._fast_lazy_load()

            target_uid = crawler.extract_uid_from_url(first_url)
            
            if target_uid:
                print(f"\n3ï¸âƒ£ ëª©í‘œ ìƒí’ˆ ì°¾ê¸°")
                print(f"  - URL: {first_url}")
                print(f"  - UID (nv_mid): {target_uid}")
                
                # ğŸ†• nv_midë¡œ ìƒí’ˆ ì°¾ì•„ì„œ í´ë¦­
                success = crawler.find_and_click_product_by_uid(target_uid)
                
                if success:
                    print(f"\nâœ… ìƒí’ˆ í˜ì´ì§€ë¡œ ì´ë™ ì„±ê³µ!")
                    print(f"  ğŸ”— í˜„ì¬ URL: {driver.current_url}")
                else:
                    print(f"\nâš ï¸  ìƒí’ˆì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
            else:
                print(f"\nâš ï¸  URLì—ì„œ UIDë¥¼ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {first_url}")
                
                # UID ì¶”ì¶œ ì‹¤íŒ¨ ì‹œ ê¸°ì¡´ ë°©ì‹ìœ¼ë¡œ ì§„í–‰
                print("\n3ï¸âƒ£ ìƒí’ˆ ëª©ë¡ ë¡œë”© ì¤‘...")
                crawler._fast_lazy_load()
                
                print("\n4ï¸âƒ£ ê°€ê²©ë¹„êµ ìƒí’ˆ ë°ì´í„° ì¶”ì¶œ")
                data = crawler._extract_store_data(page=1)
                
                if data:
                    print(f"\nâœ… {len(data)}ê°œ ìŠ¤í† ì–´ ì¶”ì¶œ ì™„ë£Œ!")
                    print(f"\nğŸ“Š ì¶”ì¶œëœ ë°ì´í„° ìƒ˜í”Œ (ì²˜ìŒ 3ê°œ):")
                    for i, item in enumerate(data[:3], 1):
                        print(f"\n[{i}]")
                        print(f"  ìƒí’ˆëª…: {item.get('ìƒí’ˆëª…', 'N/A')[:50]}")
                        print(f"  ìŠ¤í† ì–´: {item.get('ì´ë¦„', 'N/A')}")
                        print(f"  ìˆœìœ„: {item.get('ranking', 'N/A')}")
                        print(f"  ê´‘ê³ : {item.get('ê´‘ê³ ', 'N/A')}")
                        print(f"  ë¦¬ë·°ìˆ˜: {item.get('ë¦¬ë·°ìˆ˜', 'N/A')}")
                        print(f"  ì°œìˆ˜: {item.get('ì°œìˆ˜', 'N/A')}")
                else:
                    print("\nâš ï¸  ë°ì´í„° ì¶”ì¶œ ì‹¤íŒ¨")

        print("\nâœ… í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
        input("ì—”í„°ë¥¼ ëˆ„ë¥´ë©´ ì¢…ë£Œí•©ë‹ˆë‹¤...")

    except Exception as e:
        print(f"\nâŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()
        
    finally:
        print("\në“œë¼ì´ë²„ ì¢…ë£Œ ì¤‘...")
        chrome.quit_driver(driver, kill_chrome=False)
        print("âœ… ì¢…ë£Œ ì™„ë£Œ!")



if __name__ == "__main__":
    # config.json ì„¤ì • ë¡œë“œ
    config = load_config()
    
    url_list = {
        # "ë‹¤ì´ì–´ë¦¬": "https://search.shopping.naver.com/catalog/57407585768",
        "ë‹¤ì´ì–´ë¦¬": "https://search.shopping.naver.com/catalog/57407512312385768",
        "ë°”ë””ìŠ¤í¬ëŸ½": "https://smartstore.naver.com/snowqueen/products/12379736901",
        "í•œìš°ì„ ë¬¼ì„¸íŠ¸": "https://smartstore.naver.com/nabigolmart/products/9128050628",
    }
    
    # í¬ë¡¤ëŸ¬ í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    test_crawler(url_list=url_list, config=config)
