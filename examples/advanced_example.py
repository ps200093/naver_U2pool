"""
ê³ ê¸‰ ì‚¬ìš© ì˜ˆì œ
- Headless ëª¨ë“œ
- ìŠ¤í¬ë¦°ìƒ· ì €ì¥
- ì¿ í‚¤ ê´€ë¦¬
- í”„ë¡ì‹œ ì‚¬ìš© (ì¤€ë¹„)
"""
import sys
import time
from pathlib import Path
from datetime import datetime

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ pathì— ì¶”ê°€
sys.path.insert(0, str(Path(__file__).parent.parent))

from src.crawler import NaverCrawler
from src.utils import save_to_json
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC


def headless_crawling():
    """Headless ëª¨ë“œë¡œ í¬ë¡¤ë§"""
    print("\nğŸ‘» Headless ëª¨ë“œ í¬ë¡¤ë§ ì‹œì‘...")
    
    with NaverCrawler(
        headless=True,  # Headless ëª¨ë“œ
        use_mobile=True,
        device="galaxy_s24"
    ) as crawler:
        print("1ï¸âƒ£ ë„¤ì´ë²„ ì ‘ì† ì¤‘...")
        crawler.get_page("https://m.naver.com")
        
        # íƒ€ì´í‹€ í™•ì¸
        title = crawler.driver.title
        print(f"2ï¸âƒ£ í˜ì´ì§€ íƒ€ì´í‹€: {title}")
        
        # User Agent í™•ì¸
        user_agent = crawler.driver.execute_script("return navigator.userAgent")
        print(f"3ï¸âƒ£ User Agent: {user_agent[:80]}...")
        
        # ëª¨ë°”ì¼ ê°ì§€ í™•ì¸
        is_mobile = crawler.driver.execute_script(
            "return /Android|iPhone|iPad|iPod/i.test(navigator.userAgent)"
        )
        print(f"4ï¸âƒ£ ëª¨ë°”ì¼ ê°ì§€: {is_mobile}")
        
        print("\nâœ… Headless í¬ë¡¤ë§ ì™„ë£Œ!")


def take_screenshots():
    """ì—¬ëŸ¬ í˜ì´ì§€ ìŠ¤í¬ë¦°ìƒ· ì €ì¥"""
    print("\nğŸ“¸ ìŠ¤í¬ë¦°ìƒ· ì €ì¥ ì˜ˆì œ...")
    
    # ìŠ¤í¬ë¦°ìƒ· ì €ì¥ í´ë”
    screenshot_dir = Path(__file__).parent.parent / "data" / "screenshots"
    screenshot_dir.mkdir(parents=True, exist_ok=True)
    
    pages = {
        "naver_main": "https://m.naver.com",
        "naver_news": "https://m.news.naver.com",
        "naver_shopping": "https://mshopping.naver.com"
    }
    
    with NaverCrawler(
        headless=False,
        use_mobile=True,
        device="galaxy_s24"
    ) as crawler:
        for name, url in pages.items():
            print(f"\nğŸ“ {name} ì ‘ì† ì¤‘...")
            crawler.get_page(url, wait_time=2)
            
            # ìŠ¤í¬ë¦°ìƒ· ì €ì¥
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = screenshot_dir / f"{name}_{timestamp}.png"
            crawler.driver.save_screenshot(str(filename))
            
            print(f"   âœ… ìŠ¤í¬ë¦°ìƒ· ì €ì¥: {filename}")
            time.sleep(1)
    
    print(f"\nâœ… ëª¨ë“  ìŠ¤í¬ë¦°ìƒ· ì €ì¥ ì™„ë£Œ!")
    print(f"   ì €ì¥ ìœ„ì¹˜: {screenshot_dir}")


def cookie_management():
    """ì¿ í‚¤ ê´€ë¦¬ ì˜ˆì œ"""
    print("\nğŸª ì¿ í‚¤ ê´€ë¦¬ ì˜ˆì œ...")
    
    with NaverCrawler(
        headless=False,
        use_mobile=True,
        device="galaxy_s24"
    ) as crawler:
        # ë„¤ì´ë²„ ì ‘ì†
        print("1ï¸âƒ£ ë„¤ì´ë²„ ì ‘ì† ì¤‘...")
        crawler.get_page("https://m.naver.com")
        
        # ì¿ í‚¤ ê°€ì ¸ì˜¤ê¸°
        cookies = crawler.driver.get_cookies()
        print(f"2ï¸âƒ£ ì¿ í‚¤ ê°œìˆ˜: {len(cookies)}")
        
        # ì¿ í‚¤ ì •ë³´ ì¶œë ¥
        print("\nì¿ í‚¤ ëª©ë¡:")
        for cookie in cookies[:5]:  # ì²˜ìŒ 5ê°œë§Œ
            print(f"   - {cookie['name']}: {cookie['value'][:30]}...")
        
        # ì¿ í‚¤ ì €ì¥
        cookie_data = {
            "url": crawler.driver.current_url,
            "timestamp": datetime.now().isoformat(),
            "cookies": cookies
        }
        
        data_dir = Path(__file__).parent.parent / "data"
        save_to_json(cookie_data, "cookies.json")
        
        print("\nâœ… ì¿ í‚¤ ì €ì¥ ì™„ë£Œ!")
        
        # íŠ¹ì • ì¿ í‚¤ ì¶”ê°€
        print("\n3ï¸âƒ£ ì»¤ìŠ¤í…€ ì¿ í‚¤ ì¶”ê°€...")
        crawler.driver.add_cookie({
            'name': 'test_cookie',
            'value': 'test_value',
            'domain': '.naver.com'
        })
        print("   âœ… ì¿ í‚¤ ì¶”ê°€ ì™„ë£Œ!")


def extract_page_info():
    """í˜ì´ì§€ ì •ë³´ ì¶”ì¶œ"""
    print("\nğŸ“Š í˜ì´ì§€ ì •ë³´ ì¶”ì¶œ ì˜ˆì œ...")
    
    with NaverCrawler(
        headless=True,
        use_mobile=True,
        device="galaxy_s24"
    ) as crawler:
        crawler.get_page("https://m.naver.com")
        
        # JavaScriptë¡œ ë‹¤ì–‘í•œ ì •ë³´ ì¶”ì¶œ
        info = crawler.driver.execute_script("""
            return {
                // í˜ì´ì§€ ì •ë³´
                title: document.title,
                url: window.location.href,
                
                // Navigator ì •ë³´
                userAgent: navigator.userAgent,
                platform: navigator.platform,
                language: navigator.language,
                languages: navigator.languages,
                onLine: navigator.onLine,
                cookieEnabled: navigator.cookieEnabled,
                
                // ëª¨ë°”ì¼ ê´€ë ¨
                maxTouchPoints: navigator.maxTouchPoints,
                
                // í™”ë©´ ì •ë³´
                screenWidth: window.screen.width,
                screenHeight: window.screen.height,
                innerWidth: window.innerWidth,
                innerHeight: window.innerHeight,
                devicePixelRatio: window.devicePixelRatio,
                
                // Connection API
                connectionType: navigator.connection ? navigator.connection.effectiveType : 'unknown',
                
                // ê¸°íƒ€
                hardwareConcurrency: navigator.hardwareConcurrency,
                deviceMemory: navigator.deviceMemory
            };
        """)
        
        print("\n=== í˜ì´ì§€ ì •ë³´ ===")
        print(f"ì œëª©: {info['title']}")
        print(f"URL: {info['url']}")
        print()
        
        print("=== Navigator ì •ë³´ ===")
        print(f"User Agent: {info['userAgent'][:80]}...")
        print(f"í”Œë«í¼: {info['platform']}")
        print(f"ì–¸ì–´: {info['language']}")
        print(f"ì˜¨ë¼ì¸: {info['onLine']}")
        print(f"ì¿ í‚¤ í™œì„±í™”: {info['cookieEnabled']}")
        print()
        
        print("=== ëª¨ë°”ì¼ ì •ë³´ ===")
        print(f"í„°ì¹˜ í¬ì¸íŠ¸: {info['maxTouchPoints']}")
        print(f"ì—°ê²° íƒ€ì…: {info['connectionType']}")
        print()
        
        print("=== í™”ë©´ ì •ë³´ ===")
        print(f"ìŠ¤í¬ë¦°: {info['screenWidth']}x{info['screenHeight']}")
        print(f"ë·°í¬íŠ¸: {info['innerWidth']}x{info['innerHeight']}")
        print(f"Pixel Ratio: {info['devicePixelRatio']}")
        print()
        
        print("=== í•˜ë“œì›¨ì–´ ì •ë³´ ===")
        print(f"CPU ì½”ì–´: {info['hardwareConcurrency']}")
        print(f"ë©”ëª¨ë¦¬: {info['deviceMemory']}GB")
        
        # JSONìœ¼ë¡œ ì €ì¥
        data_dir = Path(__file__).parent.parent / "data"
        save_to_json(info, "page_info.json")
        
        print("\nâœ… í˜ì´ì§€ ì •ë³´ ì¶”ì¶œ ë° ì €ì¥ ì™„ë£Œ!")


def compare_mobile_desktop():
    """ëª¨ë°”ì¼ê³¼ ë°ìŠ¤í¬í†± ëª¨ë“œ ë¹„êµ"""
    print("\nğŸ”„ ëª¨ë°”ì¼ vs ë°ìŠ¤í¬í†± ë¹„êµ...")
    
    results = {}
    
    # ëª¨ë°”ì¼ ëª¨ë“œ
    print("\n1ï¸âƒ£ ëª¨ë°”ì¼ ëª¨ë“œë¡œ ì ‘ì†...")
    with NaverCrawler(
        headless=True,
        use_mobile=True,
        device="galaxy_s24"
    ) as crawler:
        crawler.get_page("https://www.naver.com")
        
        results['mobile'] = {
            'url': crawler.driver.current_url,
            'title': crawler.driver.title,
            'user_agent': crawler.driver.execute_script("return navigator.userAgent"),
            'platform': crawler.driver.execute_script("return navigator.platform"),
            'mobile_detected': crawler.driver.execute_script(
                "return /Android|iPhone|iPad|iPod/i.test(navigator.userAgent)"
            )
        }
    
    # ë°ìŠ¤í¬í†± ëª¨ë“œ
    print("2ï¸âƒ£ ë°ìŠ¤í¬í†± ëª¨ë“œë¡œ ì ‘ì†...")
    with NaverCrawler(
        headless=True,
        use_mobile=False
    ) as crawler:
        crawler.get_page("https://www.naver.com")
        
        results['desktop'] = {
            'url': crawler.driver.current_url,
            'title': crawler.driver.title,
            'user_agent': crawler.driver.execute_script("return navigator.userAgent"),
            'platform': crawler.driver.execute_script("return navigator.platform"),
            'mobile_detected': crawler.driver.execute_script(
                "return /Android|iPhone|iPad|iPod/i.test(navigator.userAgent)"
            )
        }
    
    # ê²°ê³¼ ë¹„êµ
    print("\n" + "="*60)
    print("ë¹„êµ ê²°ê³¼")
    print("="*60)
    
    print("\nğŸ“± ëª¨ë°”ì¼ ëª¨ë“œ:")
    print(f"  URL: {results['mobile']['url']}")
    print(f"  í”Œë«í¼: {results['mobile']['platform']}")
    print(f"  ëª¨ë°”ì¼ ê°ì§€: {results['mobile']['mobile_detected']}")
    print(f"  User Agent: {results['mobile']['user_agent'][:60]}...")
    
    print("\nğŸ’» ë°ìŠ¤í¬í†± ëª¨ë“œ:")
    print(f"  URL: {results['desktop']['url']}")
    print(f"  í”Œë«í¼: {results['desktop']['platform']}")
    print(f"  ëª¨ë°”ì¼ ê°ì§€: {results['desktop']['mobile_detected']}")
    print(f"  User Agent: {results['desktop']['user_agent'][:60]}...")
    
    # ì €ì¥
    data_dir = Path(__file__).parent.parent / "data"
    save_to_json(results, "mobile_vs_desktop.json")
    
    print("\nâœ… ë¹„êµ ì™„ë£Œ!")


def main():
    """ë©”ì¸ ë©”ë‰´"""
    print("\n" + "="*60)
    print("ğŸš€ ê³ ê¸‰ ì‚¬ìš© ì˜ˆì œ")
    print("="*60 + "\n")
    
    examples = {
        "1": ("Headless ëª¨ë“œ í¬ë¡¤ë§", headless_crawling),
        "2": ("ìŠ¤í¬ë¦°ìƒ· ì €ì¥", take_screenshots),
        "3": ("ì¿ í‚¤ ê´€ë¦¬", cookie_management),
        "4": ("í˜ì´ì§€ ì •ë³´ ì¶”ì¶œ", extract_page_info),
        "5": ("ëª¨ë°”ì¼ vs ë°ìŠ¤í¬í†± ë¹„êµ", compare_mobile_desktop),
    }
    
    print("ì˜ˆì œ ì„ íƒ:")
    for key, (name, _) in examples.items():
        print(f"  {key}. {name}")
    
    choice = input("\nì„ íƒí•˜ì„¸ìš” (1-5): ").strip()
    
    if choice in examples:
        name, func = examples[choice]
        print(f"\n{'='*60}")
        print(f"â–¶ï¸ {name}")
        print(f"{'='*60}")
        func()
    else:
        print("ì˜ëª»ëœ ì„ íƒì…ë‹ˆë‹¤.")


if __name__ == "__main__":
    main()

